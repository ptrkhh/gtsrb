{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t38SuFVn9Azb",
    "outputId": "a1166e95-0171-47d9-a4c4-14ead5002f8b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "GTSRB = torchvision.datasets.GTSRB(\"\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RcqQYGrpEPWM",
    "outputId": "c89d177f-2fd2-466b-d073-c0e41e87a7b0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "all_files = []\n",
    "for parent, dirs, files in os.walk(\"gtsrb\"):\n",
    "    all_files = all_files + [os.path.join(parent, i) for i in files if i.endswith(\".ppm\")]\n",
    "\n",
    "all_files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6Eys-Hq55wX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "449ayk8HKlIt",
    "outputId": "a31abac1-5bf2-4c7e-b146-be7c07164dc2"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "img = Image.open(all_files[0])\n",
    "\n",
    "\n",
    "def image_grid(paths, rows, cols):\n",
    "    imgs = [Image.open(i) for i in random.sample(paths, rows * cols)]\n",
    "    \n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols * w, rows * h))\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "image_grid(all_files, rows=3, cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmUxh7-5xcpp",
    "outputId": "015c0e70-fb1a-48db-8c4f-d5b14f65e096"
   },
   "outputs": [],
   "source": [
    "sizes = [Image.open(i).size for i in random.sample(all_files, max(500, len(all_files) // 100))]\n",
    "print(max(sizes))\n",
    "print(min(sizes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "o9gwbAFxG8Fq",
    "outputId": "8753d2df-c3e2-433d-b6c9-7616af6d3665"
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame({\"path\": all_files})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "c-cXdz9XnRAd",
    "outputId": "f6c757e1-14c8-482f-b528-cbb9c5df5466"
   },
   "outputs": [],
   "source": [
    "def get_label_from_path(the_path: str):\n",
    "    return int(the_path.split(os.sep)[-2][-2:])\n",
    "\n",
    "\n",
    "df = df.with_columns(label=pl.col('path').map_elements(get_label_from_path))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeLWAYtM_6Uf"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 15\n",
    "IMAGE_DIM = 100\n",
    "\n",
    "transforms_train = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize((IMAGE_DIM, IMAGE_DIM), antialias=True),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "transforms_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize((IMAGE_DIM, IMAGE_DIM), antialias=True),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "class GtsrbDataset(Dataset):\n",
    "    def __init__(self, df: pl.DataFrame, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx.tolist() if torch.is_tensor(idx) else idx\n",
    "\n",
    "        image, label = self.df[idx, \"path\"], self.df[idx, \"label\"]\n",
    "        image = Image.open(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "df_train, df_test = train_test_split(df)\n",
    "\n",
    "dataset_train = GtsrbDataset(df_train, transforms_train)\n",
    "dataset_test = GtsrbDataset(df_test, transforms_test)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AU0-GHAwXcok",
    "outputId": "46fd969d-b79a-4f55-90f7-5c4e9d4b9104"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_test_history = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for i, data in enumerate(dataloader_train):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss\n",
    "    total_loss = total_loss / len(dataloader_train.dataset)\n",
    "    print(f'Train Loss: {total_loss}')\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader_test:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss\n",
    "    total_loss = total_loss / len(dataloader_test.dataset)\n",
    "    print(f'Test Loss: {total_loss}')\n",
    "\n",
    "    if epoch == 0 or (total_loss < min(loss_test_history)):\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        # if epoch != 0 and (round(float(min(loss_test_history)) * 1000) == round(float(total_loss) * 1000)):\n",
    "        #     print(\"Model is no longer improving, early stopping\")\n",
    "        #     break\n",
    "    else:\n",
    "        print(\"Model performed worse, not saving this model\")\n",
    "\n",
    "    loss_test_history.append(total_loss)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(schema={\"predicted_label\":int, \"true_label\": int})\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        df = pl.concat([df, pl.DataFrame({\n",
    "            \"predicted_label\": [int(i.cpu()) for i in preds], \n",
    "            \"true_label\": labels.tolist(),\n",
    "        })])\n",
    "\n",
    "accuracy = len(df.filter((pl.col(\"predicted_label\") == pl.col(\"true_label\")))) / len(df)\n",
    "print(\"Accuracy:\", 100 * accuracy, \"%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
